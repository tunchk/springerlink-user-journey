Task1

What would be your strategy for non-functionals (cross-functionals) testing?

When it comes to selection or making a decision on what to test, how? To me it is always all about risk management.
In regards of the two testing principles:

- Exhaustive tesing is not possible 
- Testing is context dependent 

It is easy to mention that there can not be an easy one standard solution against the testing.
Therefore, I usually try to create a risk analysis, before deciding how to proceed with what to implement.

Hence, without having some answers, I will try to set a strategy by following some educated guesses.


1. List the types of non-functional tests you would perform for the
application above and how you would prioritise them?

-- Springer Link is a product where it has the entities: 
    -- A back-end api for content management
    -- A google cloud bucket
    -- A directory manager
    -- A format manager

Besides, it runs through:
    -- Browsers on PC's 
    -- Browsers on mobile devices
    -- Different subscription types
    -- In two different languages

In addition, the squads serves the software through;
    -- A CI/CD pipeline
        Where:
        -- Functional risks are tested automatically

Now it is time to make the educated guesses. Among 20+ Non-Functional Testing, in the risk perspective, I would first focus on the
end-customer focused types such as:

    -- Compatibility Testing
    -- Usability Testing
    -- Performance Testing
    -- Reliability Testing
    -- Security Testing

In other words, I would be, firstly, focusing on the variables, Availability, Reliability, Interoperability, Usability, and Security.
The main reason for focusing the aspects above is related about being customer centric. The unknown priorities might change the situation.

In my opinion the software quality has three aspects. Functional quality, Infrastructural Quality, and Process Quality.

Mainly focusing on the product's functionality.
Efficiency, Durability, Scalability, and Performance of a delivery pipeline and software environment.
Efficiency of a software development teams' SDLC.

Hence, secondly, putting aside whole functionality, I would go for:

    -- Reusability
    -- Scalability
    -- Flexibility & Portability

As a summary, first, I would go for the solutions which will enhance customers experience. After that, I would go for efficiency
and Reusability of the system. The main reason for that is, relying on the customer feedback, it would be easier to make an
educated guess over the question "How to Continue for Building new features?" or "Is it time to invest on how to automate the 
operation better, for increasing the profitibility of a product?"



2. List the tools you would use.

    -- Compatibility Testing: 
    Implementing test automation with some kind of tool " Browser Stack"
    
    -- Usability Testing: 
    We would use our own resources by designing a journey and feedback collection. However, if I 
    neead to mention a tool name, Applause or Maze can be followed. Although, my opinion is, it is better to invite people
    for a testing session.
    
    -- Performance Testing:
    It would differ regarding the tech stack or the engineering strategy. However, I personaly like to use gatling. However, 
    developers mostly like Jmeter. Back in my past, with one of my customers, we used the blazemeter and loadium very efficiently.
    
    -- Reliability Testing
    There is a need of combination. First, it is necessary to identify the journeys with product managers. After that, it is
    necessary to identify tech metrics. After that with QA engineers or developers; it is necessary to develop the scripts of load testing.
    Lastly, it is important to monitor the action against the metrics which was decided by the team. 
    For the monitoring part, there is a need of an APM tool. It can be dynatrace, appdynamics, or newrelic.
    
    -- Security Testing
    I would go for the OWASP 10. There are automated tools or services by HP that we used back in Turkey, however, this matter
    is not something that you can leave to a tool. The culture must change, and every team should be aware of the 10 rules. 
    They need to set a Definition of Done in their team, where it says; done means Security topics are done too.

    --  Reusability & Flexibility & Portability + Maintainability
    I would go for a static code analysis tool. SonarQube or codacy. Anything would do; because all the issue is about tracking 
    the code quality. If the source code is healthy, all the topics above would be easy to manage. 
    The source code health is a huge responsibility. Because, if it is not well behaved, sooner or later; you will face the 
    usual phrase of "Let's build v2"
    Every problem starts from the source code first. The procrastination over the source code problems will lead the company to
    a v2 build process.  

3. Explain where you would fit these tests in a continuous delivery
model where things go straight into production.

    -- Reusability & Scalability & Flexibility & Portability
    Constantly monitoring.
    
    -- Compatibility Testing:
    By the end of every feature testing.
    
    -- Usability Testing:
    By the end of every feature testing. 
    By the feedback of the customers and complaints.
    
    -- Performance Testing & Reliability Testing::
    By monitoring the production data.
    By every feature.

    -- Security Testing
    Constantly, during every release.
    Periodic checks.

4. How would you present this back to the team(stakeholders) - to
get maximum buy in?

In my opinion, I should not try to buy in anything. However, as a team, we should try to fit the needs in an
economic scale. The market pressure and the customer needs is something, reasonably, highly prioritised. Therefore, ofcourse, 
the product team would tend to prioritise the customer needs; by the power of data. It is possible to convince nearly
every peer. As I mentioned above, by relying on the risk basis, and collecting the related data; it is possible to show and tell 
the necessity of investment in to the the current infrastructure to the stakeholders.   