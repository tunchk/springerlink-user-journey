What kind of tests do you need for the article ingesting functionality to go live:
1. List the levels of tests that are required for the functionality
to go live.
    -- Unit Testing
    -- Integration Level- API
    -- System Tests- E2E testing
    -- Performance Testing (Although this is a non-functional testing, it is vital. Becuase, if someone cannot login 
    due to the servers performance, the customer wouldn't be able to use the functionality)
    -- Regression (Coverage should be decided by the risk basis)
    If there is a new feature going live:
    -- UAT
    -- Compatibility

2. When/where/how frequently these tests run?
    -- Unit Testing
    -- Integration Level- API
    For the testing above, I would test with every trigger of CI/CD pipeline. 

    -- System Tests- E2E testing
    For the testing above, I would run it in every new release
    
    -- UAT
    For the every new feature release

3. When/where/how does manual testing fit in?
    
    In fact, I believe manual testing is a misleading term. I mean, if you analyze the question what "a test is?" 
    it would come up as:

        "a way of discovering, by questions or practical activities, what someone knows, or what someone or something can do"
        source:"https://dictionary.cambridge.org/de/worterbuch/englisch/test"
        or
        "a medical examination of part of your body in order to find out how healthy it is or what is happening with it"

    In other words, first you need to identify what to Test!
    Afterwards, how to test it.
    Then, how to automate it.

    Therefore, the manual effort, should be necessary for identifying or researching of what to test? or how to 
    identify the risks of the system under test.

    After the identification of the process, the tests will be executed by human effort, until the engineering team
    decides how to automate the human effort.
    
    So the short answer is:
    -- The tests that are not automated.
    -- The research for identifying new tests or risks.


4. How would you ensure that the above testing strategy is a team
goal?
    -- In my opinion,it is possible with two ways. 

    -- Telling what is "The Good" for the squad?
    As I mentioned in the previous quesitons, an endless game is not possible to come out with a win. To beat
    a game, you need an ending. Otherwise, people will just quit as they will see no ending. Sooner or later they
    will quit. Preventing this quit is about border lining the game. Setting rules and goals. To be able to set the
    metrics, rules, or goals; the engineering team should now where the ship is headed. Clear understanding of the 
    company mission and vision. They need to set sprint goals accordingly. Else, the team is just coding what is 
    written, thus the team misses better solution oppurtunities. What I did in my current job was exactly this. I 
    created communication between business and product management, we set a goal togather; we told it to the squad. 
    We delivered a progressive process of product delivery.
    The engineering manager of the squad is responsible for the source code and impedement removal.
    Today, they are setting up rituals like infra stability meeting, solution design break up meeting so on and so
    forth.

    -- Finding the current maturity level of quality and setting KPI's for enhnacement:

    After the goals, borderlines are set. Just decide on squad KPI's. Then the team will come with monitoring and 
    metrics dashboard.
    Currently in my team:
    Engineering manager is following the metrics:
    Source code metrics
    Maintainability
    Availability
    The QA's are focused on:
    Bug metrics
    Automation coverage and optimization
    Dev's:
    Unit testing
    Health of unit testing 
    Mocking relevant 3rd parties
    Reliability
    After all, every peer trakcs and presents their responsiblity against the KPI's.


5. How would you make sure of the quality of the product with the
lack of a staging/preprod environment?
Although having lots of staging environments within my current company, the environment is still an essential problem.
The main reason for that is high demand in environments. However, it is possible to overcome. There are two main solutions.
Firstly, there is a need of optimization in the system level testing automation. The higher the system level testing
test cases increases the faster the test will become. Therefore, a well designed automation solution
would rely on optimization between test levels. In summary, decreasing the amount of system level tests, would increase
the pace of the test automation solution. Hence, the demand of environment will decrease. 
Secondly, we have delivered a solution around the minikube tool which enables engineers to build their own local sandbox 
environment. A complete replica of a staging environment which is running on the engineers local.
By delivering these two actions, nowadays, we are avoiding the complaints.
